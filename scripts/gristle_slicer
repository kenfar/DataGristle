#!/usr/bin/env python
"""
Gristle_slicer extracts subsets of input files based on user-specified columns and rows.  The
input csv file can be piped into the program through stdin or identified via a command line option.
The output will default to stdout, or redirected to a filename via a command line option.

The columns and rows are specified using python list slicing syntax - so individual columns or
rows can be listed as can ranges.   Inclusion or exclusion logic can be used - and even combined.

Usage: gristle_slicer [options]


{see: helpdoc.HELP_SECTION}


Main Options:
    -i, --infiles INFILE
                        One or more input files or '-' (the default) for stdin.
    -o, --outfile OUTFILE
                        The output file.  The default of '-' is stdout.
    -c, --columns SPEC  The column inclusion specification.
                        Default is ':' which includes all columns.
    -C, --excolumns SPEC
                        The column exclusion specification.
                        Default is None which excludes nothing.
    -r, --records SPEC  The record inclusion specification.
                        Default is ':' which includes all records.
    -R, --exrecords SPEC
                        The record exclusion specification.
                        Default is None which excludes nothing.

Notes:
    Supported slicing specification - for columns (-c, -C) and rows (-r, -R):
        'NumberN, StartOffset:StopOffset'
    This specification is either a comma-delimited list of individual offsets or ranges.
    Offsets are based on zero, and if negative are measured from the end of the record
    or file with -1 being the final item.  There can be N number of individual offsets.
    Ranges are a pair of offsets separated by a colon.  The first number indicates the
    starting offset, and the second number indicates the stop offset +1.


{see: helpdoc.CSV_SECTION}


{see: helpdoc.CONFIG_SECTION}


Examples:
    $ gristle_slicer -i sample.csv
                            Prints all rows and columns
    $ gristle_slicer -i sample.csv -c":5, 10:15" -C 13
                            Prints columns 0-4 and 10,11,12,14 for all records
    $ gristle_slicer -i sample.csv -C:-1
                            Prints all columns except for the last for all
                            records
    $ gristle_slicer -i sample.csv -c:5 -r-100:
                            Prints columns 0-4 for the last 100 records
    $ gristle_slicer -i sample.csv -c:5 -r-100 -d'|' --quoting=quote_all:
                            Prints columns 0-4 for the last 100 records, csv
                            dialect info (delimiter, quoting) provided manually)
    $ cat sample.csv | gristle_slicer -c:5 -r-100 -d'|' --quoting=quote_all:
                            Prints columns 0-4 for the last 100 records, csv
                            dialect info (delimiter, quoting) provided manually)
    Many more examples can be found here:
        https://github.com/kenfar/DataGristle/tree/master/examples/gristle_slicer


Licensing and Further Info:
    This source code is protected by the BSD license.  See the file "LICENSE"
    in the source code root directory for the full language or refer to it here:
       http://opensource.org/licenses/BSD-3-Clause
    Copyright 2011-2021 Ken Farmer
"""
import csv
import errno
import fileinput
from os.path import basename
from pprint import pprint as pp
from signal import signal, SIGPIPE, SIG_DFL
import sys
from typing import List, Tuple, Dict, Any, Optional, IO

import datagristle.common as comm
import datagristle.configulator as conf
import datagristle.csvhelper as csvhelper
import datagristle.file_io as file_io
import datagristle.helpdoc as helpdoc
import datagristle.location_slicer as slicer

#Ignore SIG_PIPE and don't throw exceptions on it... (http://docs.python.org/library/signal.html)
signal(SIGPIPE, SIG_DFL)

NAME = basename(__file__)
LONG_HELP = helpdoc.expand_long_help(__doc__)
SHORT_HELP = helpdoc.get_short_help_from_long(LONG_HELP)
comm.validate_python_version()



def main() -> int:

    # Set up config:
    try:
        config_manager = ConfigManager(NAME, SHORT_HELP, LONG_HELP)
        nconfig, _ = config_manager.get_config()
    except EOFError:
        return errno.ENODATA


    # Set up io:
    input_handler = file_io.InputHandler(nconfig.infiles,
                                         nconfig.dialect,
                                         return_header=True)

    output_handler = file_io.OutputHandler(nconfig.outfile, input_handler.dialect)

    # Set up slicers:
    (incl_rec_slicer,
     excl_rec_slicer,
     merged_recs) = setup_rec_slicers(nconfig.infiles,
                                      input_handler.dialect,
                                      nconfig.records,
                                      nconfig.exrecords,
                                      nconfig.max_mem_items)

    merged_cols = setup_col_slicers(nconfig.infiles,
                                    nconfig.columns,
                                    nconfig.excolumns,
                                    nconfig.header,
                                    nconfig.max_mem_items)

    if merged_recs and merged_cols:
        # Process in memory:
        all_rows = [x for x in input_handler]
        for rec_num in merged_recs:
            new_rec = process_rec_in_memory(all_rows[rec_num],
                                            merged_cols)
            if new_rec:
                output_handler.write_rec(new_rec)
    else:
        # Process in io:
        for rec in input_handler:
            new_rec = process_rec(input_handler.rec_cnt - 1,
                                  incl_rec_slicer,
                                  excl_rec_slicer,
                                  rec,
                                  merged_cols)
            if new_rec:
                output_handler.write_rec(new_rec)

    input_handler.close()
    output_handler.close()

    return 0



def setup_rec_slicers(infiles: List[str],
                      dialect: csv.Dialect,
                      config_records: str,
                      config_exrecords: str,
                      max_mem_items: int) -> Tuple[slicer.SpecProcessor,
                                                   slicer.SpecProcessor,
                                                   List[int]]:
    """  Sets up the slicer objects (inclusion & exclusion) for
         recs as well as the merged_recs_specs for columns.

         Then counts records if negative slice references exist and calls
         the spec adjuster.
    """

    # first parse the config items;
    records   = config_records.split(',')
    exrecords = config_exrecords.split(',') if config_exrecords else []

    # set up row slicing:
    rec_cnt = None
    if (slicer.spec_has_negatives(records)
            or slicer.spec_has_negatives(exrecords)
            or slicer.spec_has_unbounded_range(records)
            or slicer.spec_has_unbounded_range(exrecords)):
        rec_cnt = get_rec_count(infiles, dialect)
    incl_rec_slicer = slicer.SpecProcessor(records,
                                           'incl_rec_spec',
                                           header=None,
                                           infiles=infiles,
                                           actual_item_count=rec_cnt,
                                           max_mem_item_count=max_mem_items)
    excl_rec_slicer = slicer.SpecProcessor(exrecords,
                                           'excl_rec_spec',
                                           header=None,
                                           infiles=infiles,
                                           actual_item_count=rec_cnt,
                                           max_mem_item_count=max_mem_items)

    # merge column specs: 
    merged_col_spec = merger(incl_rec_slicer.ordered_spec, excl_rec_slicer.ordered_spec)

    return (incl_rec_slicer,
            excl_rec_slicer,
            merged_col_spec)



def setup_col_slicers(infiles: List[str],
                      config_columns: str,
                      config_excolumns: str,
                      config_header: csvhelper.Header,
                      max_mem_items: int) -> List[int]:
    """  Sets up the 2 slicer objects: inclusion & exclusion for
         recs and the merged_cols for columns.

         Then counts records and columns if negative slice references
         exist and calls the spec adjuster.
    """

    # first parse the config items;
    columns   = config_columns.split(',')
    excolumns = config_excolumns.split(',') if config_excolumns else []

    # set up the slicers:
    col_count = len(config_header.field_names)-1
    incl_col_slicer = slicer.SpecProcessor(columns,
                                           'incl_col_spec',
                                           config_header,
                                           infiles,
                                           actual_item_count=col_count,
                                           max_mem_item_count=max_mem_items)
    excl_col_slicer = slicer.SpecProcessor(excolumns,
                                           'excl_col_spec',
                                           config_header,
                                           infiles,
                                           actual_item_count=col_count,
                                           max_mem_item_count=max_mem_items)

    # merge column specs:
    merged_col_spec = merger(incl_col_slicer.ordered_spec, excl_col_slicer.ordered_spec)
    if incl_col_slicer.memory_overflow or excl_col_slicer.memory_overflow:
        comm.abort('Error: too many columns for memory.',
                   f'It is currently limited to {incl_col_slicer.max_in_mem_processing_recs}. '
                   'You can increase the number of cols allowed with the --max-mem-recs option')

    return merged_col_spec




def merger(incl_ordered_spec, excl_ordered_spec):
    pp('---------- merger ------------------')
    pp(incl_ordered_spec)
    pp(excl_ordered_spec)
    pp('------------------------------------')
    merged_cols = []
    if incl_ordered_spec is None or excl_ordered_spec is None:
        return None
    for col in incl_ordered_spec:
        if col in excl_ordered_spec:
            continue
        else:
            merged_cols.append(int(col))
    return merged_cols



def get_rec_count(files: List[str],
                  dialect: csv.Dialect) -> int:
    """ Gets record counts for input files.
        - Counts have an offset of 0
    """
    rec_cnt = -1
    for _ in csv.reader(fileinput.input(files), dialect):
        rec_cnt += 1
    fileinput.close()
    return rec_cnt



def process_rec(rec_number: int,
                incl_rec_slicer: slicer.SpecProcessor,
                excl_rec_slicer: slicer.SpecProcessor,
                rec: List[str],
                merged_col_spec) -> Optional[List[str]]:
    """ Evaluates all the specifications against a single record
        from the input file.  First it applies inclusion & exclusion
        specifications against the record, then it applies inclusion
        & exclusion specifications against each column.
        Input:
            - rec_number:      used for rec specs
            - incl_rec_spec
            - excl_rec_spec
            - rec:             a list of all columns from the record
            - merged_cols:     simple list of which columns to include
        Output:
            - if the rec_number fails:  None
            - if the rec_number passes: a list of the columns that qualified
    """
    # minimal validation
    assert int(rec_number) >= 0
    assert merged_col_spec

    # reject record if it isn't in the inclusion spec
    if not incl_rec_slicer.spec_evaluator(rec_number):
        return None

    # reject record if it is in the exclusion spec
    if excl_rec_slicer.spec_evaluator(rec_number):
        return None

    output_rec = []
    for col_number in merged_col_spec:
        output_rec.append(rec[col_number])

    if output_rec:
        return output_rec
    else:
        return None  # don't return empty list



def process_rec_in_memory(rec: List,
                          merged_col_spec) -> Optional[List[str]]:
    """ Evaluates all the specifications against a single record
        from the input file.  First it applies inclusion & exclusion
        specifications against the record, then it applies inclusion
        & exclusion specifications against each column.
        Input:
            - rec_number:      used for rec specs
            - incl_rec_spec
            - excl_rec_spec
            - rec:             a list of all columns from the record
            - merged_cols:     simple list of which columns to include
        Output:
            - if the rec_number fails:  None
            - if the rec_number passes: a list of the columns that qualified
    """
    pp('******* Process in memory ***********')
    pp(merged_col_spec)
    output_rec = []
    for col_number in merged_col_spec:
        try:
            output_rec.append(rec[col_number])
        except IndexError:
            # This indicates a spec was provided for cols not in the record
            pass

    if output_rec:
        return output_rec
    else:
        return None  # don't return empty list




class ConfigManager(conf.Config):


    def define_user_config(self) -> None:
        """ Defines the user config or metadata.

        Does not get the user input.
        """
        self.add_standard_metadata('infiles')
        self.add_standard_metadata('outfile')

        self.add_custom_metadata(name='columns',
                                 short_name='c',
                                 default=':',
                                 type=str)
        self.add_custom_metadata(name='excolumns',
                                 short_name='C',
                                 default='',
                                 type=str)
        self.add_custom_metadata(name='records',
                                 short_name='r',
                                 default=':',
                                 type=str)
        self.add_custom_metadata(name='exrecords',
                                 short_name='R',
                                 default='',
                                 type=str)
        self.add_custom_metadata(name='max_mem_items',
                                 default=1000000,
                                 type=int)

        self.add_standard_metadata('verbosity')
        self.add_all_config_configs()
        self.add_all_csv_configs()
        self.add_all_help_configs()


    def extend_config(self) -> None:

        self.generate_csv_dialect_config()
        self.generate_csv_header_config()

    def validate_custom_config(self, config) -> None:

        if config['infiles'] == '-':
            if ('-' in config['columns']
                or '-' in config['excolumns']
                or '-' in config['records']
                or '-' in config['exrecords']):
                comm.abort('Error: negative values not supported with stdin')




if __name__ == '__main__':
    sys.exit(main())
